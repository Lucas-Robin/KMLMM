Train on 40000 samples, validate on 20000 samples
Epoch 1/100
train_acc = 0.940475
5s - loss: 0.4056 - acc: 0.8887 - val_loss: 0.2213 - val_acc: 0.9377
Epoch 2/100
train_acc = 0.961850
4s - loss: 0.1809 - acc: 0.9488 - val_loss: 0.1608 - val_acc: 0.9547
Epoch 3/100
train_acc = 0.972575
4s - loss: 0.1289 - acc: 0.9634 - val_loss: 0.1305 - val_acc: 0.9626
Epoch 4/100
train_acc = 0.980650
4s - loss: 0.0988 - acc: 0.9728 - val_loss: 0.1110 - val_acc: 0.9681
Epoch 5/100
train_acc = 0.983300
4s - loss: 0.0774 - acc: 0.9790 - val_loss: 0.1078 - val_acc: 0.9684
Epoch 6/100
train_acc = 0.986350
4s - loss: 0.0625 - acc: 0.9828 - val_loss: 0.0976 - val_acc: 0.9721
Epoch 7/100
train_acc = 0.990350
4s - loss: 0.0505 - acc: 0.9864 - val_loss: 0.0911 - val_acc: 0.9720
Epoch 8/100
train_acc = 0.990225
4s - loss: 0.0414 - acc: 0.9892 - val_loss: 0.0926 - val_acc: 0.9719
Epoch 9/100
train_acc = 0.994775
4s - loss: 0.0345 - acc: 0.9916 - val_loss: 0.0835 - val_acc: 0.9751
Epoch 10/100
train_acc = 0.995475
4s - loss: 0.0290 - acc: 0.9931 - val_loss: 0.0841 - val_acc: 0.9753
Epoch 11/100
train_acc = 0.996075
5s - loss: 0.0234 - acc: 0.9950 - val_loss: 0.0854 - val_acc: 0.9743
Epoch 12/100
train_acc = 0.997425
5s - loss: 0.0192 - acc: 0.9960 - val_loss: 0.0802 - val_acc: 0.9767
Epoch 13/100
train_acc = 0.998425
5s - loss: 0.0155 - acc: 0.9970 - val_loss: 0.0792 - val_acc: 0.9763
Epoch 14/100
train_acc = 0.999250
5s - loss: 0.0124 - acc: 0.9982 - val_loss: 0.0807 - val_acc: 0.9766
Epoch 15/100
train_acc = 0.999350
5s - loss: 0.0106 - acc: 0.9984 - val_loss: 0.0811 - val_acc: 0.9768
Epoch 16/100
train_acc = 0.999500
5s - loss: 0.0085 - acc: 0.9990 - val_loss: 0.0796 - val_acc: 0.9780
Epoch 17/100
train_acc = 0.999575
5s - loss: 0.0069 - acc: 0.9994 - val_loss: 0.0799 - val_acc: 0.9779
Epoch 18/100
train_acc = 0.999775
4s - loss: 0.0058 - acc: 0.9995 - val_loss: 0.0802 - val_acc: 0.9785
Epoch 19/100
train_acc = 0.999775
4s - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0822 - val_acc: 0.9788
Epoch 20/100
train_acc = 0.999975
4s - loss: 0.0039 - acc: 0.9999 - val_loss: 0.0859 - val_acc: 0.9774
Epoch 21/100
train_acc = 1.000000
4s - loss: 0.0034 - acc: 0.9999 - val_loss: 0.0827 - val_acc: 0.9787
Epoch 22/100
train_acc = 1.000000
4s - loss: 0.0028 - acc: 0.9999 - val_loss: 0.0830 - val_acc: 0.9788
Epoch 23/100
train_acc = 1.000000
4s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0848 - val_acc: 0.9786
Epoch 24/100
train_acc = 1.000000
4s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9784
Epoch 25/100
train_acc = 1.000000
5s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9794
Epoch 26/100
train_acc = 1.000000
5s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9785
Epoch 27/100
train_acc = 1.000000
4s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9784
Epoch 28/100
train_acc = 0.999850
4s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.0944 - val_acc: 0.9767
Epoch 29/100
train_acc = 0.994400
4s - loss: 0.0102 - acc: 0.9971 - val_loss: 0.1117 - val_acc: 0.9723
Epoch 30/100
train_acc = 0.998850
5s - loss: 0.0130 - acc: 0.9959 - val_loss: 0.0950 - val_acc: 0.9767
Epoch 31/100
train_acc = 0.999975
5s - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0933 - val_acc: 0.9792
Epoch 32/100
train_acc = 1.000000
4s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9798
Epoch 33/100
train_acc = 1.000000
4s - loss: 6.7708e-04 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9797
Epoch 34/100
train_acc = 1.000000
4s - loss: 5.5133e-04 - acc: 1.0000 - val_loss: 0.0916 - val_acc: 0.9802
Epoch 35/100
train_acc = 1.000000
4s - loss: 4.8018e-04 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9805
Epoch 36/100
train_acc = 1.000000
4s - loss: 4.4776e-04 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9800
Epoch 37/100
train_acc = 1.000000
4s - loss: 3.9439e-04 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 0.9803
Epoch 38/100
train_acc = 1.000000
4s - loss: 3.5969e-04 - acc: 1.0000 - val_loss: 0.0941 - val_acc: 0.9800
Epoch 39/100
train_acc = 1.000000
4s - loss: 3.3194e-04 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9799
Epoch 40/100
train_acc = 1.000000
4s - loss: 3.1440e-04 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9800
Epoch 41/100
train_acc = 1.000000
4s - loss: 2.8585e-04 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9798
Epoch 42/100
train_acc = 1.000000
4s - loss: 2.5894e-04 - acc: 1.0000 - val_loss: 0.0958 - val_acc: 0.9797
Epoch 43/100
train_acc = 1.000000
4s - loss: 2.3741e-04 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 0.9800
Epoch 44/100
train_acc = 1.000000
4s - loss: 2.2268e-04 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9799
Epoch 45/100
train_acc = 1.000000
4s - loss: 2.0411e-04 - acc: 1.0000 - val_loss: 0.0977 - val_acc: 0.9796
Epoch 46/100
train_acc = 1.000000
4s - loss: 1.8876e-04 - acc: 1.0000 - val_loss: 0.0989 - val_acc: 0.9799
Epoch 47/100
train_acc = 1.000000
4s - loss: 1.7216e-04 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 0.9799
Epoch 48/100
train_acc = 1.000000
4s - loss: 1.5996e-04 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9797
Epoch 49/100
train_acc = 1.000000
4s - loss: 1.4707e-04 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9800
Epoch 50/100
train_acc = 1.000000
4s - loss: 1.3422e-04 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9799
Epoch 51/100
train_acc = 1.000000
4s - loss: 1.2099e-04 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9802
Epoch 52/100
train_acc = 1.000000
4s - loss: 1.1225e-04 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9799
Epoch 53/100
train_acc = 1.000000
4s - loss: 1.0253e-04 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9804
Epoch 54/100
train_acc = 1.000000
4s - loss: 9.5611e-05 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9797
Epoch 55/100
train_acc = 1.000000
4s - loss: 9.5949e-05 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 0.9802
Epoch 56/100
train_acc = 0.984975
4s - loss: 0.0144 - acc: 0.9959 - val_loss: 0.1845 - val_acc: 0.9641
Epoch 57/100
train_acc = 0.999325
4s - loss: 0.0174 - acc: 0.9944 - val_loss: 0.1107 - val_acc: 0.9766
Epoch 58/100
train_acc = 0.999875
4s - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1052 - val_acc: 0.9784
Epoch 59/100
train_acc = 1.000000
4s - loss: 5.6363e-04 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9788
Epoch 60/100
train_acc = 1.000000
4s - loss: 2.7470e-04 - acc: 1.0000 - val_loss: 0.1030 - val_acc: 0.9792
Epoch 61/100
train_acc = 1.000000
4s - loss: 2.2047e-04 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9793
Epoch 62/100
train_acc = 1.000000
4s - loss: 1.9110e-04 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9793
Epoch 63/100
train_acc = 1.000000
4s - loss: 1.6996e-04 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9793
Epoch 64/100
train_acc = 1.000000
4s - loss: 1.5325e-04 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9792
Epoch 65/100
train_acc = 1.000000
4s - loss: 1.3933e-04 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9792
Epoch 66/100
train_acc = 1.000000
4s - loss: 1.2726e-04 - acc: 1.0000 - val_loss: 0.1057 - val_acc: 0.9792
Epoch 67/100
train_acc = 1.000000
4s - loss: 1.1685e-04 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9794
Epoch 68/100
train_acc = 1.000000
4s - loss: 1.0831e-04 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9790
Epoch 69/100
train_acc = 1.000000
4s - loss: 1.0034e-04 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9792
Epoch 70/100
train_acc = 1.000000
4s - loss: 9.2436e-05 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9791
Epoch 71/100
train_acc = 1.000000
4s - loss: 8.5552e-05 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9792
Epoch 72/100
train_acc = 1.000000
4s - loss: 7.9633e-05 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9792
Epoch 73/100
train_acc = 1.000000
4s - loss: 7.4217e-05 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9793
Epoch 74/100
train_acc = 1.000000
4s - loss: 6.9741e-05 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9792
Epoch 75/100
train_acc = 1.000000
4s - loss: 6.5127e-05 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 0.9794
Epoch 76/100
train_acc = 1.000000
4s - loss: 6.0488e-05 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9794
Epoch 77/100
train_acc = 1.000000
4s - loss: 5.7062e-05 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9793
Epoch 78/100
train_acc = 1.000000
4s - loss: 5.2947e-05 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9792
Epoch 79/100
train_acc = 1.000000
4s - loss: 4.9671e-05 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9797
Epoch 80/100
train_acc = 1.000000
4s - loss: 4.5446e-05 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9795
Epoch 81/100
train_acc = 1.000000
4s - loss: 4.2624e-05 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9800
Epoch 82/100
train_acc = 1.000000
4s - loss: 3.9554e-05 - acc: 1.0000 - val_loss: 0.1125 - val_acc: 0.9797
Epoch 83/100
train_acc = 1.000000
4s - loss: 3.6944e-05 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9791
Epoch 84/100
train_acc = 1.000000
4s - loss: 3.4247e-05 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9793
Epoch 85/100
train_acc = 1.000000
4s - loss: 3.2284e-05 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9799
Epoch 86/100
train_acc = 1.000000
4s - loss: 2.9771e-05 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9798
Epoch 87/100
train_acc = 1.000000
4s - loss: 2.7562e-05 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 0.9798
Epoch 88/100
train_acc = 1.000000
4s - loss: 2.5559e-05 - acc: 1.0000 - val_loss: 0.1149 - val_acc: 0.9795
Epoch 89/100
train_acc = 1.000000
4s - loss: 2.3642e-05 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9800
Epoch 90/100
train_acc = 1.000000
4s - loss: 2.2004e-05 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9795
Epoch 91/100
train_acc = 1.000000
5s - loss: 2.0125e-05 - acc: 1.0000 - val_loss: 0.1168 - val_acc: 0.9795
Epoch 92/100
train_acc = 1.000000
6s - loss: 1.8933e-05 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9794
Epoch 93/100
train_acc = 1.000000
4s - loss: 1.7298e-05 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 0.9798
Epoch 94/100
train_acc = 1.000000
4s - loss: 1.5751e-05 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 0.9797
Epoch 95/100
train_acc = 1.000000
4s - loss: 1.4773e-05 - acc: 1.0000 - val_loss: 0.1182 - val_acc: 0.9801
Epoch 96/100
train_acc = 1.000000
4s - loss: 1.3549e-05 - acc: 1.0000 - val_loss: 0.1191 - val_acc: 0.9796
Epoch 97/100
train_acc = 1.000000
4s - loss: 1.2436e-05 - acc: 1.0000 - val_loss: 0.1201 - val_acc: 0.9797
Epoch 98/100
train_acc = 1.000000
4s - loss: 1.1458e-05 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9798
Epoch 99/100
train_acc = 1.000000
4s - loss: 1.0671e-05 - acc: 1.0000 - val_loss: 0.1207 - val_acc: 0.9795
Epoch 100/100
train_acc = 1.000000
4s - loss: 9.6548e-06 - acc: 1.0000 - val_loss: 0.1211 - val_acc: 0.9796
Error: 1.94%
[0.94047499999999995, 0.96184999999999998, 0.97257499999999997, 0.98065000000000002, 0.98329999999999995, 0.98634999999999995, 0.99034999999999995, 0.99022500000000002, 0.99477499999999996, 0.995475, 0.99607500000000004, 0.99742500000000001, 0.99842500000000001, 0.99924999999999997, 0.99934999999999996, 0.99950000000000006, 0.99957499999999999, 0.99977499999999997, 0.99977499999999997, 0.99997499999999995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99985000000000002, 0.99439999999999995, 0.99885000000000002, 0.99997499999999995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98497500000000004, 0.99932500000000002, 0.99987499999999996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
[0.93774999976158147, 0.9547499936819076, 0.96259999632835391, 0.96810000598430634, 0.96840000689029693, 0.97210000813007358, 0.97195000946521759, 0.97185000896453855, 0.97505001127719881, 0.97530001401901245, 0.97430001080036166, 0.97665001213550573, 0.97630001306533809, 0.97660001337528224, 0.97675001144409179, 0.9780000120401382, 0.97790001690387729, 0.97850001513957974, 0.97880001485347745, 0.97740001380443575, 0.97865001499652859, 0.97875001549720764, 0.97860001385211948, 0.97840001642704011, 0.97935001492500307, 0.97850001633167272, 0.97835001587867731, 0.97670001208782198, 0.9722500091791153, 0.97665001392364503, 0.97915001451969141, 0.97975001454353328, 0.9797000157833099, 0.98020001590251926, 0.98045001566410062, 0.98000001549720761, 0.98025001525878908, 0.9799500161409378, 0.97990001678466798, 0.97995001554489136, 0.97975001573562626, 0.97970001518726346, 0.98000001609325404, 0.97990001559257511, 0.97955001592636104, 0.97985001564025875, 0.97990001618862155, 0.97965001523494721, 0.9799500161409378, 0.97990001559257511, 0.98015001535415647, 0.97990001559257511, 0.98040001571178437, 0.9797000157833099, 0.98015001535415647, 0.96410000026226039, 0.97655001282691956, 0.97835001349449158, 0.97880001425743102, 0.97920001387596134, 0.97925001382827759, 0.97925001382827759, 0.97925001323223115, 0.97915001332759855, 0.97920001447200777, 0.97915001392364498, 0.97935001492500307, 0.97895001471042631, 0.97915001571178439, 0.97905001401901248, 0.97915001511573796, 0.97915001511573796, 0.97925001502037046, 0.97920001506805421, 0.9793500155210495, 0.97935001492500307, 0.97930001556873325, 0.97915001571178439, 0.97965001583099365, 0.97950001537799836, 0.97995001554489136, 0.97965001523494721, 0.97910001635551458, 0.97930001497268682, 0.97990001559257511, 0.97975001573562626, 0.97980001509189607, 0.97950001597404479, 0.98000001490116118, 0.97950001537799836, 0.97950001537799836, 0.97935001611709593, 0.97975001454353328, 0.97970001518726346, 0.98005001425743099, 0.97955001533031461, 0.97965001523494721, 0.97975001513957982, 0.97945001423358913, 0.97955001473426817]
Train on 40000 samples, validate on 20000 samples
Epoch 1/100
train_acc = 0.954125
26s - loss: 0.3221 - acc: 0.9088 - val_loss: 0.1773 - val_acc: 0.9482
Epoch 2/100
train_acc = 0.973600
30s - loss: 0.1342 - acc: 0.9613 - val_loss: 0.1271 - val_acc: 0.9643
Epoch 3/100
train_acc = 0.983150
30s - loss: 0.0862 - acc: 0.9754 - val_loss: 0.1044 - val_acc: 0.9698
Epoch 4/100
train_acc = 0.989200
30s - loss: 0.0601 - acc: 0.9826 - val_loss: 0.0907 - val_acc: 0.9729
Epoch 5/100
train_acc = 0.993075
30s - loss: 0.0434 - acc: 0.9884 - val_loss: 0.0816 - val_acc: 0.9751
Epoch 6/100
train_acc = 0.993175
30s - loss: 0.0317 - acc: 0.9917 - val_loss: 0.0891 - val_acc: 0.9733
Epoch 7/100
train_acc = 0.996950
19s - loss: 0.0237 - acc: 0.9945 - val_loss: 0.0778 - val_acc: 0.9768
Epoch 8/100
train_acc = 0.997675
10s - loss: 0.0159 - acc: 0.9966 - val_loss: 0.0771 - val_acc: 0.9770
Epoch 9/100
train_acc = 0.998300
10s - loss: 0.0118 - acc: 0.9976 - val_loss: 0.0754 - val_acc: 0.9771
Epoch 10/100
train_acc = 0.999300
10s - loss: 0.0094 - acc: 0.9984 - val_loss: 0.0751 - val_acc: 0.9777
Epoch 11/100
train_acc = 0.999900
10s - loss: 0.0061 - acc: 0.9994 - val_loss: 0.0747 - val_acc: 0.9791
Epoch 12/100
train_acc = 0.999825
10s - loss: 0.0039 - acc: 0.9998 - val_loss: 0.0732 - val_acc: 0.9786
Epoch 13/100
train_acc = 0.999925
11s - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0721 - val_acc: 0.9800
Epoch 14/100
train_acc = 0.999950
10s - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0748 - val_acc: 0.9795
Epoch 15/100
train_acc = 1.000000
10s - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0746 - val_acc: 0.9800
Epoch 16/100
train_acc = 1.000000
10s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9805
Epoch 17/100
train_acc = 1.000000
9s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9795
Epoch 18/100
train_acc = 1.000000
9s - loss: 9.6781e-04 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9805
Epoch 19/100
train_acc = 0.998675
10s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0844 - val_acc: 0.9786
Epoch 20/100
train_acc = 1.000000
10s - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0771 - val_acc: 0.9804
Epoch 21/100
train_acc = 1.000000
11s - loss: 7.7595e-04 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9804
Epoch 22/100
train_acc = 1.000000
10s - loss: 5.6954e-04 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9806
Epoch 23/100
train_acc = 1.000000
9s - loss: 4.2308e-04 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 0.9809
Epoch 24/100
train_acc = 1.000000
9s - loss: 3.4994e-04 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9809
Epoch 25/100
train_acc = 1.000000
10s - loss: 3.0378e-04 - acc: 1.0000 - val_loss: 0.0815 - val_acc: 0.9809
Epoch 26/100
train_acc = 1.000000
10s - loss: 2.7170e-04 - acc: 1.0000 - val_loss: 0.0815 - val_acc: 0.9811
Epoch 27/100
train_acc = 1.000000
10s - loss: 2.3819e-04 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9812
Epoch 28/100
train_acc = 1.000000
10s - loss: 2.1340e-04 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 0.9810
Epoch 29/100
train_acc = 1.000000
10s - loss: 1.9883e-04 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9810
Epoch 30/100
train_acc = 1.000000
10s - loss: 1.7035e-04 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9809
Epoch 31/100
train_acc = 1.000000
10s - loss: 1.5014e-04 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9812
Epoch 32/100
train_acc = 1.000000
10s - loss: 1.3700e-04 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9812
Epoch 33/100
train_acc = 1.000000
11s - loss: 1.2003e-04 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 0.9813
Epoch 34/100
train_acc = 1.000000
11s - loss: 1.0694e-04 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9814
Epoch 35/100
train_acc = 1.000000
11s - loss: 9.4208e-05 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 0.9810
Epoch 36/100
train_acc = 1.000000
11s - loss: 8.4953e-05 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9813
Epoch 37/100
train_acc = 1.000000
11s - loss: 7.7177e-05 - acc: 1.0000 - val_loss: 0.0892 - val_acc: 0.9812
Epoch 38/100
train_acc = 1.000000
11s - loss: 7.2448e-05 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 0.9813
Epoch 39/100
train_acc = 1.000000
11s - loss: 6.0743e-05 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9811
Epoch 40/100
train_acc = 1.000000
11s - loss: 5.3970e-05 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 0.9816
Epoch 41/100
train_acc = 1.000000
11s - loss: 4.8795e-05 - acc: 1.0000 - val_loss: 0.0910 - val_acc: 0.9810
Epoch 42/100
train_acc = 1.000000
11s - loss: 4.4024e-05 - acc: 1.0000 - val_loss: 0.0916 - val_acc: 0.9816
Epoch 43/100
train_acc = 1.000000
12s - loss: 3.7954e-05 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9814
Epoch 44/100
train_acc = 1.000000
11s - loss: 3.5139e-05 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 0.9815
Epoch 45/100
train_acc = 1.000000
12s - loss: 3.0634e-05 - acc: 1.0000 - val_loss: 0.0951 - val_acc: 0.9810
Epoch 46/100
train_acc = 1.000000
11s - loss: 2.7176e-05 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9813
Epoch 47/100
train_acc = 1.000000
12s - loss: 2.4303e-05 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9816
Epoch 48/100
train_acc = 1.000000
11s - loss: 2.1803e-05 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9816
Epoch 49/100
train_acc = 1.000000
12s - loss: 1.9183e-05 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9817
Epoch 50/100
train_acc = 1.000000
11s - loss: 1.7219e-05 - acc: 1.0000 - val_loss: 0.0972 - val_acc: 0.9816
Epoch 51/100
train_acc = 1.000000
11s - loss: 1.5483e-05 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9814
Epoch 52/100
train_acc = 1.000000
12s - loss: 1.4245e-05 - acc: 1.0000 - val_loss: 0.0988 - val_acc: 0.9814
Epoch 53/100
train_acc = 1.000000
11s - loss: 1.2386e-05 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9817
Epoch 54/100
train_acc = 1.000000
12s - loss: 1.0975e-05 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 0.9815
Epoch 55/100
train_acc = 1.000000
12s - loss: 9.8844e-06 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9815
Epoch 56/100
train_acc = 1.000000
11s - loss: 8.9566e-06 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9816
Epoch 57/100
train_acc = 1.000000
11s - loss: 8.0459e-06 - acc: 1.0000 - val_loss: 0.1027 - val_acc: 0.9817
Epoch 58/100
train_acc = 1.000000
11s - loss: 7.0173e-06 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 0.9815
Epoch 59/100
train_acc = 1.000000
10s - loss: 6.3416e-06 - acc: 1.0000 - val_loss: 0.1034 - val_acc: 0.9818
Epoch 60/100
train_acc = 1.000000
11s - loss: 5.7292e-06 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9817
Epoch 61/100
train_acc = 1.000000
11s - loss: 5.1127e-06 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9820
Epoch 62/100
train_acc = 1.000000
11s - loss: 4.6124e-06 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9819
Epoch 63/100
train_acc = 1.000000
11s - loss: 4.0581e-06 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9817
Epoch 64/100
train_acc = 1.000000
11s - loss: 3.6625e-06 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9817
Epoch 65/100
train_acc = 1.000000
11s - loss: 3.3154e-06 - acc: 1.0000 - val_loss: 0.1073 - val_acc: 0.9815
Epoch 66/100
train_acc = 1.000000
10s - loss: 3.0101e-06 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9819
Epoch 67/100
train_acc = 1.000000
10s - loss: 2.6722e-06 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9815
Epoch 68/100
train_acc = 1.000000
11s - loss: 2.3760e-06 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9818
Epoch 69/100
train_acc = 1.000000
11s - loss: 2.1802e-06 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9816
Epoch 70/100
train_acc = 1.000000
11s - loss: 1.9581e-06 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9817
Epoch 71/100
train_acc = 1.000000
11s - loss: 1.7520e-06 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9816
Epoch 72/100
train_acc = 1.000000
10s - loss: 1.5865e-06 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9817
Epoch 73/100
train_acc = 1.000000
10s - loss: 1.4373e-06 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 0.9814
Epoch 74/100
train_acc = 1.000000
10s - loss: 1.2936e-06 - acc: 1.0000 - val_loss: 0.1125 - val_acc: 0.9818
Epoch 75/100
train_acc = 1.000000
10s - loss: 1.1494e-06 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9816
Epoch 76/100
train_acc = 1.000000
11s - loss: 1.0496e-06 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9816
Epoch 77/100
train_acc = 1.000000
11s - loss: 9.6625e-07 - acc: 1.0000 - val_loss: 0.1138 - val_acc: 0.9820
Epoch 78/100
train_acc = 1.000000
12s - loss: 8.6878e-07 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9820
Epoch 79/100
train_acc = 1.000000
11s - loss: 7.9301e-07 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9816
Epoch 80/100
train_acc = 1.000000
11s - loss: 7.1267e-07 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9819
Epoch 81/100
train_acc = 1.000000
11s - loss: 6.5223e-07 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9817
Epoch 82/100
train_acc = 1.000000
10s - loss: 6.0506e-07 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9820
Epoch 83/100
train_acc = 1.000000
10s - loss: 5.4647e-07 - acc: 1.0000 - val_loss: 0.1166 - val_acc: 0.9818
Epoch 84/100
train_acc = 1.000000
10s - loss: 5.0737e-07 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9819
Epoch 85/100
train_acc = 1.000000
11s - loss: 4.6231e-07 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9819
Epoch 86/100
train_acc = 1.000000
11s - loss: 4.2742e-07 - acc: 1.0000 - val_loss: 0.1195 - val_acc: 0.9816
Epoch 87/100
train_acc = 1.000000
11s - loss: 3.9468e-07 - acc: 1.0000 - val_loss: 0.1195 - val_acc: 0.9819
Epoch 88/100
train_acc = 1.000000
11s - loss: 3.6921e-07 - acc: 1.0000 - val_loss: 0.1201 - val_acc: 0.9817
Epoch 89/100
train_acc = 1.000000
11s - loss: 3.3981e-07 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9817
Epoch 90/100
train_acc = 1.000000
11s - loss: 3.1563e-07 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9820
Epoch 91/100
train_acc = 1.000000
11s - loss: 3.0341e-07 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9819
Epoch 92/100
train_acc = 1.000000
11s - loss: 2.8193e-07 - acc: 1.0000 - val_loss: 0.1221 - val_acc: 0.9820
Epoch 93/100
train_acc = 1.000000
11s - loss: 2.5832e-07 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 0.9818
Epoch 94/100
train_acc = 1.000000
12s - loss: 2.4392e-07 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 0.9821
Epoch 95/100
train_acc = 1.000000
12s - loss: 2.3095e-07 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9817
Epoch 96/100
train_acc = 1.000000
11s - loss: 2.2045e-07 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 0.9823
Epoch 97/100
train_acc = 1.000000
11s - loss: 2.0905e-07 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9819
Epoch 98/100
train_acc = 1.000000
11s - loss: 1.9811e-07 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 0.9820
Epoch 99/100
train_acc = 1.000000
11s - loss: 1.9027e-07 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9820
Epoch 100/100
train_acc = 1.000000
11s - loss: 1.8176e-07 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9819
Error: 1.75%
[0.954125, 0.97360000000000002, 0.98314999999999997, 0.98919999999999997, 0.99307500000000004, 0.99317500000000003, 0.99695, 0.99767499999999998, 0.99829999999999997, 0.99929999999999997, 0.99990000000000001, 0.99982499999999996, 0.99992499999999995, 0.99995000000000001, 1.0, 1.0, 1.0, 1.0, 0.99867499999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
[0.94819999456405635, 0.96434999942779542, 0.96975000798702238, 0.97285001099109647, 0.97505001187324525, 0.97325000643730164, 0.97680001437664032, 0.97700001299381256, 0.97705001294612881, 0.9777000141143799, 0.97910001218318943, 0.97860001444816591, 0.97995001494884493, 0.97945001363754269, 0.98000001430511474, 0.98045001387596131, 0.97950001478195192, 0.98045001626014705, 0.97860001444816591, 0.9803500139713287, 0.98035001635551455, 0.98060001671314234, 0.98090001463890075, 0.9808500146865845, 0.98090001404285432, 0.98105001509189604, 0.9812000149488449, 0.98095001518726344, 0.9810000151395798, 0.98090001463890075, 0.98120001554489134, 0.98115001499652865, 0.98125001490116115, 0.98135001420974732, 0.980950014591217, 0.98125001490116115, 0.98120001435279847, 0.98125001430511472, 0.98110001564025884, 0.98155001461505886, 0.98095001399517057, 0.98160001456737522, 0.98140001475811001, 0.98145001471042637, 0.98100001454353336, 0.98125001490116115, 0.98160001456737522, 0.98160001456737522, 0.98165001451969147, 0.98160001456737522, 0.98135001480579376, 0.98135001480579376, 0.98170001447200772, 0.98150001466274261, 0.98145001471042637, 0.98155001461505886, 0.98165001511573791, 0.98150001466274261, 0.98180001378059389, 0.98170001447200772, 0.98200001418590543, 0.98185001432895658, 0.98165001451969147, 0.98170001447200772, 0.98150001406669618, 0.98190001487731937, 0.98150001466274261, 0.98180001437664033, 0.98155001461505886, 0.98170001447200772, 0.98155001461505886, 0.98170001447200772, 0.98140001475811001, 0.98180001497268676, 0.98160001456737522, 0.98160001516342166, 0.98200001418590543, 0.98200001478195187, 0.98155001461505886, 0.98185001432895658, 0.98170001447200772, 0.98195001482963562, 0.98180001437664033, 0.98190001368522639, 0.98185001492500301, 0.98160001456737522, 0.98190001487731937, 0.98165001451969147, 0.98170001506805415, 0.98200001478195187, 0.98190001487731937, 0.98195001482963562, 0.9818000155687332, 0.98205001533031466, 0.98170001447200772, 0.98230001509189602, 0.98190001547336581, 0.9820000153779983, 0.9820000153779983, 0.98190001487731937]
Train on 40000 samples, validate on 20000 samples
Epoch 1/100
train_acc = 0.947375
6s - loss: 0.3769 - acc: 0.8948 - val_loss: 0.1907 - val_acc: 0.9436
Epoch 2/100
train_acc = 0.970650
5s - loss: 0.1451 - acc: 0.9583 - val_loss: 0.1290 - val_acc: 0.9621
Epoch 3/100
train_acc = 0.978225
5s - loss: 0.0959 - acc: 0.9718 - val_loss: 0.1161 - val_acc: 0.9647
Epoch 4/100
train_acc = 0.982075
5s - loss: 0.0682 - acc: 0.9805 - val_loss: 0.1075 - val_acc: 0.9676
Epoch 5/100
train_acc = 0.988450
5s - loss: 0.0508 - acc: 0.9852 - val_loss: 0.0926 - val_acc: 0.9713
Epoch 6/100
train_acc = 0.993000
5s - loss: 0.0374 - acc: 0.9890 - val_loss: 0.0862 - val_acc: 0.9736
Epoch 7/100
train_acc = 0.996125
5s - loss: 0.0267 - acc: 0.9928 - val_loss: 0.0790 - val_acc: 0.9776
Epoch 8/100
train_acc = 0.996950
5s - loss: 0.0210 - acc: 0.9943 - val_loss: 0.0834 - val_acc: 0.9758
Epoch 9/100
train_acc = 0.997925
5s - loss: 0.0171 - acc: 0.9954 - val_loss: 0.0800 - val_acc: 0.9773
Epoch 10/100
train_acc = 0.996650
5s - loss: 0.0121 - acc: 0.9972 - val_loss: 0.0911 - val_acc: 0.9750
Epoch 11/100
train_acc = 0.998950
4s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0861 - val_acc: 0.9768
Epoch 12/100
train_acc = 0.998525
5s - loss: 0.0059 - acc: 0.9990 - val_loss: 0.0898 - val_acc: 0.9770
Epoch 13/100
train_acc = 0.999575
5s - loss: 0.0059 - acc: 0.9988 - val_loss: 0.0858 - val_acc: 0.9778
Epoch 14/100
train_acc = 0.997725
4s - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0984 - val_acc: 0.9743
Epoch 15/100
train_acc = 0.997275
5s - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0972 - val_acc: 0.9736
Epoch 16/100
train_acc = 0.995350
5s - loss: 0.0100 - acc: 0.9969 - val_loss: 0.1233 - val_acc: 0.9708
Epoch 17/100
train_acc = 0.996350
5s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.1140 - val_acc: 0.9731
Epoch 18/100
train_acc = 0.999800
5s - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0929 - val_acc: 0.9779
Epoch 19/100
train_acc = 0.999900
5s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.0950 - val_acc: 0.9782
Epoch 20/100
train_acc = 1.000000
5s - loss: 5.7350e-04 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 0.9797
Epoch 21/100
train_acc = 1.000000
5s - loss: 3.0786e-04 - acc: 1.0000 - val_loss: 0.0911 - val_acc: 0.9796
Epoch 22/100
train_acc = 1.000000
5s - loss: 2.4274e-04 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9799
Epoch 23/100
train_acc = 1.000000
5s - loss: 2.0577e-04 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9801
Epoch 24/100
train_acc = 1.000000
5s - loss: 1.7806e-04 - acc: 1.0000 - val_loss: 0.0944 - val_acc: 0.9801
Epoch 25/100
train_acc = 1.000000
4s - loss: 1.5605e-04 - acc: 1.0000 - val_loss: 0.0959 - val_acc: 0.9799
Epoch 26/100
train_acc = 1.000000
5s - loss: 1.3966e-04 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9801
Epoch 27/100
train_acc = 1.000000
5s - loss: 1.2523e-04 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 0.9799
Epoch 28/100
train_acc = 1.000000
5s - loss: 1.1189e-04 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9800
Epoch 29/100
train_acc = 1.000000
5s - loss: 1.0305e-04 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9799
Epoch 30/100
train_acc = 1.000000
5s - loss: 9.2468e-05 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9801
Epoch 31/100
train_acc = 1.000000
5s - loss: 8.4888e-05 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9802
Epoch 32/100
train_acc = 1.000000
5s - loss: 7.6320e-05 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9801
Epoch 33/100
train_acc = 1.000000
5s - loss: 6.8595e-05 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9799
Epoch 34/100
train_acc = 1.000000
5s - loss: 6.2962e-05 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9803
Epoch 35/100
train_acc = 1.000000
5s - loss: 5.6776e-05 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9801
Epoch 36/100
train_acc = 1.000000
5s - loss: 5.2271e-05 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9801
Epoch 37/100
train_acc = 1.000000
5s - loss: 4.7430e-05 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9802
Epoch 38/100
train_acc = 1.000000
5s - loss: 4.2864e-05 - acc: 1.0000 - val_loss: 0.1042 - val_acc: 0.9803
Epoch 39/100
train_acc = 1.000000
5s - loss: 3.8677e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9801
Epoch 40/100
train_acc = 1.000000
5s - loss: 3.6350e-05 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9805
Epoch 41/100
train_acc = 1.000000
4s - loss: 3.1407e-05 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9800
Epoch 42/100
train_acc = 1.000000
5s - loss: 2.8687e-05 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 0.9801
Epoch 43/100
train_acc = 1.000000
5s - loss: 2.5735e-05 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9802
Epoch 44/100
train_acc = 1.000000
5s - loss: 2.4335e-05 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9804
Epoch 45/100
train_acc = 1.000000
5s - loss: 2.1444e-05 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9806
Epoch 46/100
train_acc = 1.000000
5s - loss: 1.9149e-05 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9806
Epoch 47/100
train_acc = 1.000000
5s - loss: 1.7162e-05 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9805
Epoch 48/100
train_acc = 1.000000
5s - loss: 1.5439e-05 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 0.9802
Epoch 49/100
train_acc = 1.000000
5s - loss: 1.3897e-05 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9802
Epoch 50/100
train_acc = 1.000000
5s - loss: 1.2509e-05 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9803
Epoch 51/100
train_acc = 1.000000
5s - loss: 1.1276e-05 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9804
Epoch 52/100
train_acc = 1.000000
5s - loss: 1.0112e-05 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 0.9806
Epoch 53/100
train_acc = 1.000000
4s - loss: 9.1526e-06 - acc: 1.0000 - val_loss: 0.1153 - val_acc: 0.9803
Epoch 54/100
train_acc = 1.000000
5s - loss: 8.2454e-06 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9806
Epoch 55/100
train_acc = 1.000000
5s - loss: 7.3389e-06 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 0.9806
Epoch 56/100
train_acc = 1.000000
5s - loss: 6.6264e-06 - acc: 1.0000 - val_loss: 0.1180 - val_acc: 0.9803
Epoch 57/100
train_acc = 1.000000
5s - loss: 5.9364e-06 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 0.9803
Epoch 58/100
train_acc = 1.000000
4s - loss: 5.2552e-06 - acc: 1.0000 - val_loss: 0.1191 - val_acc: 0.9804
Epoch 59/100
train_acc = 1.000000
5s - loss: 4.7089e-06 - acc: 1.0000 - val_loss: 0.1197 - val_acc: 0.9802
Epoch 60/100
train_acc = 1.000000
6s - loss: 4.3002e-06 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9804
Epoch 61/100
train_acc = 1.000000
5s - loss: 3.8597e-06 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9803
Epoch 62/100
train_acc = 1.000000
5s - loss: 3.4883e-06 - acc: 1.0000 - val_loss: 0.1231 - val_acc: 0.9805
Epoch 63/100
train_acc = 1.000000
5s - loss: 3.0706e-06 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 0.9801
Epoch 64/100
train_acc = 1.000000
5s - loss: 2.7778e-06 - acc: 1.0000 - val_loss: 0.1245 - val_acc: 0.9803
Epoch 65/100
train_acc = 1.000000
5s - loss: 2.4988e-06 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 0.9804
Epoch 66/100
train_acc = 1.000000
5s - loss: 2.2260e-06 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9803
Epoch 67/100
train_acc = 1.000000
5s - loss: 1.9893e-06 - acc: 1.0000 - val_loss: 0.1264 - val_acc: 0.9804
Epoch 68/100
train_acc = 1.000000
6s - loss: 1.8051e-06 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 0.9799
Epoch 69/100
train_acc = 1.000000
5s - loss: 1.6369e-06 - acc: 1.0000 - val_loss: 0.1279 - val_acc: 0.9801
Epoch 70/100
train_acc = 1.000000
5s - loss: 1.4467e-06 - acc: 1.0000 - val_loss: 0.1282 - val_acc: 0.9803
Epoch 71/100
train_acc = 1.000000
5s - loss: 1.3175e-06 - acc: 1.0000 - val_loss: 0.1300 - val_acc: 0.9802
Epoch 72/100
train_acc = 1.000000
5s - loss: 1.1719e-06 - acc: 1.0000 - val_loss: 0.1290 - val_acc: 0.9802
Epoch 73/100
train_acc = 1.000000
4s - loss: 1.0558e-06 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 0.9800
Epoch 74/100
train_acc = 1.000000
4s - loss: 9.5792e-07 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9802
Epoch 75/100
train_acc = 1.000000
4s - loss: 8.7167e-07 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 0.9801
Epoch 76/100
train_acc = 1.000000
5s - loss: 7.8322e-07 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9800
Epoch 77/100
train_acc = 1.000000
5s - loss: 7.1641e-07 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9803
Epoch 78/100
train_acc = 1.000000
5s - loss: 6.5199e-07 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9802
Epoch 79/100
train_acc = 1.000000
5s - loss: 5.9596e-07 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 0.9800
Epoch 80/100
train_acc = 1.000000
5s - loss: 5.4443e-07 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9800
Epoch 81/100
train_acc = 1.000000
5s - loss: 4.9598e-07 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9803
Epoch 82/100
train_acc = 1.000000
4s - loss: 4.5775e-07 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9801
Epoch 83/100
train_acc = 1.000000
4s - loss: 4.1757e-07 - acc: 1.0000 - val_loss: 0.1372 - val_acc: 0.9801
Epoch 84/100
train_acc = 1.000000
4s - loss: 3.8385e-07 - acc: 1.0000 - val_loss: 0.1377 - val_acc: 0.9802
Epoch 85/100
train_acc = 1.000000
5s - loss: 3.5454e-07 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9800
Epoch 86/100
train_acc = 1.000000
4s - loss: 3.3069e-07 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9799
Epoch 87/100
train_acc = 1.000000
4s - loss: 3.0497e-07 - acc: 1.0000 - val_loss: 0.1392 - val_acc: 0.9801
Epoch 88/100
train_acc = 1.000000
5s - loss: 2.8177e-07 - acc: 1.0000 - val_loss: 0.1404 - val_acc: 0.9802
Epoch 89/100
train_acc = 1.000000
5s - loss: 2.6533e-07 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 0.9801
Epoch 90/100
train_acc = 1.000000
5s - loss: 2.4719e-07 - acc: 1.0000 - val_loss: 0.1403 - val_acc: 0.9800
Epoch 91/100
train_acc = 1.000000
5s - loss: 2.3423e-07 - acc: 1.0000 - val_loss: 0.1417 - val_acc: 0.9802
Epoch 92/100
train_acc = 1.000000
4s - loss: 2.2034e-07 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9801
Epoch 93/100
train_acc = 1.000000
4s - loss: 2.0894e-07 - acc: 1.0000 - val_loss: 0.1427 - val_acc: 0.9799
Epoch 94/100
train_acc = 1.000000
5s - loss: 1.9808e-07 - acc: 1.0000 - val_loss: 0.1446 - val_acc: 0.9799
Epoch 95/100
train_acc = 1.000000
4s - loss: 1.8842e-07 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9801
Epoch 96/100
train_acc = 1.000000
5s - loss: 1.8073e-07 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9801
Epoch 97/100
train_acc = 1.000000
5s - loss: 1.7434e-07 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9801
Epoch 98/100
train_acc = 1.000000
6s - loss: 1.6683e-07 - acc: 1.0000 - val_loss: 0.1451 - val_acc: 0.9800
Epoch 99/100
train_acc = 1.000000
5s - loss: 1.6134e-07 - acc: 1.0000 - val_loss: 0.1458 - val_acc: 0.9803
Epoch 100/100
train_acc = 1.000000
5s - loss: 1.5636e-07 - acc: 1.0000 - val_loss: 0.1465 - val_acc: 0.9799
Error: 1.95%
[0.94737499999999997, 0.97065000000000001, 0.97822500000000001, 0.98207500000000003, 0.98845000000000005, 0.99299999999999999, 0.99612500000000004, 0.99695, 0.99792499999999995, 0.99665000000000004, 0.99895, 0.998525, 0.99957499999999999, 0.99772499999999997, 0.99727500000000002, 0.99534999999999996, 0.99634999999999996, 0.99980000000000002, 0.99990000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
[0.94359999656677251, 0.96209999382495881, 0.96469999670982365, 0.96755000233650212, 0.9713000082969665, 0.97355000793933866, 0.97760001182556155, 0.97575001060962674, 0.97730001091957097, 0.97495001077651977, 0.97675001204013823, 0.97700001299381256, 0.97775001168251041, 0.97430000662803651, 0.97360001027584075, 0.97080000638961794, 0.97310000896453852, 0.97790001273155214, 0.97820001423358915, 0.97970001399517059, 0.97960001409053798, 0.97985001385211945, 0.98005001366138456, 0.98010001420974735, 0.97990001440048213, 0.98005001425743099, 0.97985001504421232, 0.98000001430511474, 0.97985001444816588, 0.98010001480579378, 0.98020001411437985, 0.98010001480579378, 0.97990001440048213, 0.98025001525878908, 0.98005001425743099, 0.98010001420974735, 0.98015001535415647, 0.98025001406669621, 0.98005001425743099, 0.98050001502037043, 0.98000001370906831, 0.98010001420974735, 0.98015001475811003, 0.98035001337528227, 0.98060001373291017, 0.98060001373291017, 0.98050001323223113, 0.9801500141620636, 0.98015001356601716, 0.98030001401901246, 0.98040001392364506, 0.98060001373291017, 0.98030001342296602, 0.98055001318454738, 0.98055001378059392, 0.98030001282691959, 0.98025001406669621, 0.98035001337528227, 0.98015001356601716, 0.98040001332759852, 0.98025001287460323, 0.98045001327991488, 0.98010001242160794, 0.98025001287460323, 0.98035001337528227, 0.98025001287460323, 0.98035001337528227, 0.9799000120162964, 0.98010001242160794, 0.98025001227855679, 0.98020001351833341, 0.98020001232624054, 0.97995001256465908, 0.98020001351833341, 0.98005001246929169, 0.980000011920929, 0.98025001347064977, 0.9801500123739243, 0.98000001251697544, 0.97995001256465908, 0.98025001168251036, 0.98005001246929169, 0.98010001242160794, 0.98020001232624054, 0.980000011920929, 0.97985001266002658, 0.98005001246929169, 0.9801500123739243, 0.98005001246929169, 0.98000001251697544, 0.9801500123739243, 0.98010001242160794, 0.97985001266002658, 0.97985001325607302, 0.98005001246929169, 0.98005001246929169, 0.98005001187324525, 0.97995001196861264, 0.98025001227855679, 0.97990001261234283]
Train on 40000 samples, validate on 20000 samples
Epoch 1/100
train_acc = 0.914150
48s - loss: 0.7478 - acc: 0.7635 - val_loss: 0.2867 - val_acc: 0.9139
Epoch 2/100
train_acc = 0.948100
45s - loss: 0.2166 - acc: 0.9350 - val_loss: 0.1676 - val_acc: 0.9481
Epoch 3/100
train_acc = 0.961950
44s - loss: 0.1486 - acc: 0.9551 - val_loss: 0.1266 - val_acc: 0.9618
Epoch 4/100
train_acc = 0.970075
43s - loss: 0.1201 - acc: 0.9634 - val_loss: 0.1053 - val_acc: 0.9685
Epoch 5/100
train_acc = 0.972650
43s - loss: 0.1013 - acc: 0.9698 - val_loss: 0.0965 - val_acc: 0.9711
Epoch 6/100
train_acc = 0.972625
43s - loss: 0.0908 - acc: 0.9728 - val_loss: 0.0963 - val_acc: 0.9708
Epoch 7/100
train_acc = 0.977000
42s - loss: 0.0848 - acc: 0.9744 - val_loss: 0.0879 - val_acc: 0.9742
Epoch 8/100
train_acc = 0.977900
37s - loss: 0.0766 - acc: 0.9773 - val_loss: 0.0817 - val_acc: 0.9753
Epoch 9/100
train_acc = 0.979325
38s - loss: 0.0706 - acc: 0.9786 - val_loss: 0.0769 - val_acc: 0.9781
Epoch 10/100
train_acc = 0.981050
37s - loss: 0.0661 - acc: 0.9799 - val_loss: 0.0736 - val_acc: 0.9785
Epoch 11/100
train_acc = 0.983925
37s - loss: 0.0627 - acc: 0.9809 - val_loss: 0.0677 - val_acc: 0.9810
Epoch 12/100
train_acc = 0.983350
37s - loss: 0.0592 - acc: 0.9820 - val_loss: 0.0695 - val_acc: 0.9793
Epoch 13/100
train_acc = 0.980875
36s - loss: 0.0581 - acc: 0.9826 - val_loss: 0.0778 - val_acc: 0.9774
Epoch 14/100
train_acc = 0.985450
37s - loss: 0.0532 - acc: 0.9841 - val_loss: 0.0646 - val_acc: 0.9808
Epoch 15/100
train_acc = 0.987125
37s - loss: 0.0506 - acc: 0.9849 - val_loss: 0.0611 - val_acc: 0.9830
Epoch 16/100
train_acc = 0.986125
37s - loss: 0.0494 - acc: 0.9850 - val_loss: 0.0620 - val_acc: 0.9823
Epoch 17/100
train_acc = 0.985625
36s - loss: 0.0461 - acc: 0.9860 - val_loss: 0.0665 - val_acc: 0.9807
Epoch 18/100
train_acc = 0.987400
36s - loss: 0.0448 - acc: 0.9867 - val_loss: 0.0615 - val_acc: 0.9827
Epoch 19/100
train_acc = 0.984575
37s - loss: 0.0435 - acc: 0.9866 - val_loss: 0.0685 - val_acc: 0.9791
Epoch 20/100
train_acc = 0.989800
36s - loss: 0.0446 - acc: 0.9859 - val_loss: 0.0587 - val_acc: 0.9843
Epoch 21/100
train_acc = 0.989350
38s - loss: 0.0413 - acc: 0.9875 - val_loss: 0.0577 - val_acc: 0.9836
Epoch 22/100
train_acc = 0.990475
37s - loss: 0.0391 - acc: 0.9879 - val_loss: 0.0560 - val_acc: 0.9848
Epoch 23/100
train_acc = 0.988975
37s - loss: 0.0386 - acc: 0.9880 - val_loss: 0.0592 - val_acc: 0.9837
Epoch 24/100
train_acc = 0.989175
38s - loss: 0.0368 - acc: 0.9886 - val_loss: 0.0593 - val_acc: 0.9842
Epoch 25/100
train_acc = 0.991375
38s - loss: 0.0353 - acc: 0.9892 - val_loss: 0.0573 - val_acc: 0.9842
Epoch 26/100
train_acc = 0.991175
37s - loss: 0.0335 - acc: 0.9895 - val_loss: 0.0569 - val_acc: 0.9842
Epoch 27/100
train_acc = 0.991650
35s - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0552 - val_acc: 0.9841
Epoch 28/100
train_acc = 0.989750
37s - loss: 0.0360 - acc: 0.9887 - val_loss: 0.0608 - val_acc: 0.9827
Epoch 29/100
train_acc = 0.991000
37s - loss: 0.0337 - acc: 0.9897 - val_loss: 0.0570 - val_acc: 0.9849
Epoch 30/100
train_acc = 0.992575
36s - loss: 0.0303 - acc: 0.9911 - val_loss: 0.0540 - val_acc: 0.9850
Epoch 31/100
train_acc = 0.992475
36s - loss: 0.0282 - acc: 0.9914 - val_loss: 0.0557 - val_acc: 0.9856
Epoch 32/100
train_acc = 0.993275
37s - loss: 0.0289 - acc: 0.9910 - val_loss: 0.0542 - val_acc: 0.9856
Epoch 33/100
train_acc = 0.993500
37s - loss: 0.0272 - acc: 0.9918 - val_loss: 0.0542 - val_acc: 0.9853
Epoch 34/100
train_acc = 0.992000
36s - loss: 0.0275 - acc: 0.9912 - val_loss: 0.0611 - val_acc: 0.9839
Epoch 35/100
train_acc = 0.990850
36s - loss: 0.0277 - acc: 0.9911 - val_loss: 0.0640 - val_acc: 0.9825
Epoch 36/100
train_acc = 0.992125
37s - loss: 0.0267 - acc: 0.9913 - val_loss: 0.0598 - val_acc: 0.9849
Epoch 37/100
train_acc = 0.992000
37s - loss: 0.0251 - acc: 0.9923 - val_loss: 0.0627 - val_acc: 0.9839
Epoch 38/100
train_acc = 0.992850
37s - loss: 0.0239 - acc: 0.9928 - val_loss: 0.0603 - val_acc: 0.9849
Epoch 39/100
train_acc = 0.992850
37s - loss: 0.0236 - acc: 0.9925 - val_loss: 0.0587 - val_acc: 0.9843
Epoch 40/100
train_acc = 0.993750
37s - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0580 - val_acc: 0.9850
Epoch 41/100
train_acc = 0.995425
36s - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0550 - val_acc: 0.9861
Epoch 42/100
train_acc = 0.992675
37s - loss: 0.0208 - acc: 0.9931 - val_loss: 0.0625 - val_acc: 0.9840
Epoch 43/100
train_acc = 0.994625
37s - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0567 - val_acc: 0.9857
Epoch 44/100
train_acc = 0.994250
39s - loss: 0.0200 - acc: 0.9936 - val_loss: 0.0614 - val_acc: 0.9850
Epoch 45/100
train_acc = 0.994700
37s - loss: 0.0201 - acc: 0.9933 - val_loss: 0.0572 - val_acc: 0.9854
Epoch 46/100
train_acc = 0.994925
36s - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0595 - val_acc: 0.9864
Epoch 47/100
train_acc = 0.995425
37s - loss: 0.0197 - acc: 0.9937 - val_loss: 0.0574 - val_acc: 0.9845
Epoch 48/100
train_acc = 0.996225
37s - loss: 0.0165 - acc: 0.9952 - val_loss: 0.0584 - val_acc: 0.9861
Epoch 49/100
train_acc = 0.992125
37s - loss: 0.0173 - acc: 0.9946 - val_loss: 0.0696 - val_acc: 0.9840
Epoch 50/100
train_acc = 0.995300
37s - loss: 0.0176 - acc: 0.9948 - val_loss: 0.0638 - val_acc: 0.9851
Epoch 51/100
train_acc = 0.995725
37s - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0623 - val_acc: 0.9849
Epoch 52/100
train_acc = 0.993975
38s - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0669 - val_acc: 0.9836
Epoch 53/100
train_acc = 0.993875
37s - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0688 - val_acc: 0.9838
Epoch 54/100
train_acc = 0.995450
37s - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0696 - val_acc: 0.9835
Epoch 55/100
train_acc = 0.996625
37s - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0593 - val_acc: 0.9861
Epoch 56/100
train_acc = 0.996050
37s - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0664 - val_acc: 0.9853
Epoch 57/100
train_acc = 0.996425
36s - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0640 - val_acc: 0.9855
Epoch 58/100
train_acc = 0.997425
37s - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0644 - val_acc: 0.9855
Epoch 59/100
train_acc = 0.997175
36s - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0631 - val_acc: 0.9854
Epoch 60/100
train_acc = 0.997575
36s - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0646 - val_acc: 0.9850
Epoch 61/100
train_acc = 0.997150
36s - loss: 0.0140 - acc: 0.9952 - val_loss: 0.0645 - val_acc: 0.9856
Epoch 62/100
train_acc = 0.997875
37s - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0636 - val_acc: 0.9860
Epoch 63/100
train_acc = 0.996650
37s - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0662 - val_acc: 0.9850
Epoch 64/100
train_acc = 0.997450
37s - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0657 - val_acc: 0.9862
Epoch 65/100
train_acc = 0.996225
37s - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0770 - val_acc: 0.9843
Epoch 66/100
train_acc = 0.995650
36s - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0670 - val_acc: 0.9847
Epoch 67/100
train_acc = 0.996750
36s - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0702 - val_acc: 0.9857
Epoch 68/100
train_acc = 0.996475
38s - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0712 - val_acc: 0.9853
Epoch 69/100
train_acc = 0.996450
38s - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0800 - val_acc: 0.9849
Epoch 70/100
train_acc = 0.997850
37s - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0705 - val_acc: 0.9863
Epoch 71/100
train_acc = 0.997775
37s - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0701 - val_acc: 0.9852
Epoch 72/100
train_acc = 0.997225
37s - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0759 - val_acc: 0.9852
Epoch 73/100
train_acc = 0.996825
36s - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0771 - val_acc: 0.9845
Epoch 74/100
train_acc = 0.998325
37s - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0728 - val_acc: 0.9858
Epoch 75/100
train_acc = 0.994350
37s - loss: 0.0107 - acc: 0.9963 - val_loss: 0.0801 - val_acc: 0.9837
Epoch 76/100
train_acc = 0.994700
37s - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0875 - val_acc: 0.9837
Epoch 77/100
train_acc = 0.998625
36s - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0713 - val_acc: 0.9861
Epoch 78/100
train_acc = 0.998550
37s - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0722 - val_acc: 0.9862
Epoch 79/100
train_acc = 0.997650
37s - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0765 - val_acc: 0.9853
Epoch 80/100
train_acc = 0.998600
38s - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0798 - val_acc: 0.9855
Epoch 81/100
train_acc = 0.996275
38s - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0844 - val_acc: 0.9843
Epoch 82/100
train_acc = 0.998675
37s - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0765 - val_acc: 0.9858
Epoch 83/100
train_acc = 0.997625
37s - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0814 - val_acc: 0.9855
Epoch 84/100
train_acc = 0.997925
35s - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0832 - val_acc: 0.9846
Epoch 85/100
train_acc = 0.993525
37s - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0988 - val_acc: 0.9818
Epoch 86/100
train_acc = 0.995375
36s - loss: 0.0097 - acc: 0.9964 - val_loss: 0.0852 - val_acc: 0.9837
Epoch 87/100
train_acc = 0.998425
38s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0823 - val_acc: 0.9858
Epoch 88/100
train_acc = 0.999625
37s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0786 - val_acc: 0.9866
Epoch 89/100
train_acc = 0.999125
36s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0795 - val_acc: 0.9856
Epoch 90/100
train_acc = 0.999000
38s - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0819 - val_acc: 0.9857
Epoch 91/100
train_acc = 0.999350
35s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0796 - val_acc: 0.9866
Epoch 92/100
train_acc = 0.999150
37s - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0828 - val_acc: 0.9858
Epoch 93/100
train_acc = 0.996425
36s - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0871 - val_acc: 0.9841
Epoch 94/100
train_acc = 0.997750
37s - loss: 0.0086 - acc: 0.9967 - val_loss: 0.0823 - val_acc: 0.9850
Epoch 95/100
train_acc = 0.996200
36s - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0931 - val_acc: 0.9837
Epoch 96/100
train_acc = 0.998175
37s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0900 - val_acc: 0.9851
Epoch 97/100
train_acc = 0.997500
37s - loss: 0.0097 - acc: 0.9966 - val_loss: 0.0881 - val_acc: 0.9844
Epoch 98/100
train_acc = 0.999075
36s - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0848 - val_acc: 0.9856
Epoch 99/100
train_acc = 0.999375
36s - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0872 - val_acc: 0.9856
Epoch 100/100
train_acc = 0.999500
37s - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0884 - val_acc: 0.9865
Error: 1.37%
[0.91415000000000002, 0.94810000000000005, 0.96194999999999997, 0.97007500000000002, 0.97265000000000001, 0.97262499999999996, 0.97699999999999998, 0.97789999999999999, 0.979325, 0.98104999999999998, 0.98392500000000005, 0.98334999999999995, 0.98087500000000005, 0.98545000000000005, 0.98712500000000003, 0.98612500000000003, 0.98562499999999997, 0.98740000000000006, 0.98457499999999998, 0.98980000000000001, 0.98934999999999995, 0.99047499999999999, 0.98897500000000005, 0.98917500000000003, 0.99137500000000001, 0.99117500000000003, 0.99165000000000003, 0.98975000000000002, 0.99099999999999999, 0.99257499999999999, 0.992475, 0.99327500000000002, 0.99350000000000005, 0.99199999999999999, 0.99085000000000001, 0.99212500000000003, 0.99199999999999999, 0.99285000000000001, 0.99285000000000001, 0.99375000000000002, 0.995425, 0.99267499999999997, 0.99462499999999998, 0.99424999999999997, 0.99470000000000003, 0.99492499999999995, 0.995425, 0.99622500000000003, 0.99212500000000003, 0.99529999999999996, 0.99572499999999997, 0.99397500000000005, 0.99387499999999995, 0.99544999999999995, 0.99662499999999998, 0.99604999999999999, 0.99642500000000001, 0.99742500000000001, 0.99717500000000003, 0.99757499999999999, 0.99714999999999998, 0.99787499999999996, 0.99665000000000004, 0.99744999999999995, 0.99622500000000003, 0.99565000000000003, 0.99675000000000002, 0.996475, 0.99644999999999995, 0.99785000000000001, 0.99777499999999997, 0.99722500000000003, 0.99682499999999996, 0.99832500000000002, 0.99434999999999996, 0.99470000000000003, 0.99862499999999998, 0.99855000000000005, 0.99765000000000004, 0.99860000000000004, 0.99627500000000002, 0.99867499999999998, 0.99762499999999998, 0.99792499999999995, 0.99352499999999999, 0.99537500000000001, 0.99842500000000001, 0.99962499999999999, 0.99912500000000004, 0.999, 0.99934999999999996, 0.99914999999999998, 0.99642500000000001, 0.99775000000000003, 0.99619999999999997, 0.99817500000000003, 0.99750000000000005, 0.99907500000000005, 0.99937500000000001, 0.99950000000000006]
[0.91390000343322753, 0.94814999699592595, 0.96184999644756319, 0.96850000321865082, 0.97110000669956209, 0.97075000405311584, 0.97415000855922695, 0.97530001044273373, 0.97810001075267794, 0.9784500104188919, 0.98100001215934751, 0.9793000131845474, 0.97735000967979435, 0.98075001060962674, 0.98300001084804534, 0.9822500139474869, 0.98070001304149623, 0.98270001411437991, 0.97910001039505001, 0.98425001382827759, 0.98355001389980312, 0.98480001389980321, 0.98370001316070554, 0.98420001208782193, 0.98420001208782193, 0.98420001208782193, 0.98405001282691951, 0.98265001416206355, 0.98485001266002659, 0.98500001192092901, 0.98555001139640808, 0.98560001194477076, 0.98525001287460323, 0.98385001182556153, 0.98250001311302182, 0.98485001325607302, 0.9838500130176544, 0.98485001325607302, 0.98430001199245454, 0.98500001370906831, 0.98610001206398012, 0.98400001287460326, 0.98565001189708712, 0.98495001196861265, 0.98540001153945922, 0.98640001177787784, 0.98445001184940339, 0.98605001270771031, 0.98400001168251039, 0.98510001242160794, 0.98490001261234283, 0.98355001330375669, 0.9837500131130219, 0.98350001096725459, 0.98605001151561733, 0.98525001287460323, 0.9855000126361847, 0.98550001323223113, 0.98535001218318941, 0.98495001196861265, 0.98560001134872433, 0.98600001156330108, 0.98500001192092901, 0.98620001137256619, 0.98425001263618472, 0.98465001285076137, 0.98565001368522642, 0.98525001108646393, 0.98485001146793361, 0.98625001132488255, 0.98520001113414768, 0.98515001356601717, 0.98445001065731053, 0.98575001239776616, 0.98370001256465911, 0.98370001316070554, 0.98610001206398012, 0.9861500108242035, 0.98525001168251036, 0.98545001208782201, 0.98430001199245454, 0.98580001115798954, 0.98550001084804539, 0.98455001294612887, 0.98180001318454746, 0.98370001256465911, 0.98575001239776616, 0.9865500116348267, 0.98555001080036164, 0.98565001189708712, 0.98655001103878026, 0.98575001120567318, 0.984100011587143, 0.98500001132488246, 0.98370001256465911, 0.98505001187324526, 0.98435001194477079, 0.98560001254081731, 0.98560001194477076, 0.98650001049041747]
Train on 40000 samples, validate on 20000 samples
Epoch 1/100
train_acc = 0.935000
49s - loss: 0.5502 - acc: 0.8378 - val_loss: 0.2182 - val_acc: 0.9356
Epoch 2/100
train_acc = 0.964250
49s - loss: 0.1645 - acc: 0.9503 - val_loss: 0.1234 - val_acc: 0.9640
Epoch 3/100
train_acc = 0.973825
50s - loss: 0.1054 - acc: 0.9675 - val_loss: 0.0902 - val_acc: 0.9729
Epoch 4/100
train_acc = 0.981075
48s - loss: 0.0811 - acc: 0.9753 - val_loss: 0.0733 - val_acc: 0.9782
Epoch 5/100
train_acc = 0.983025
49s - loss: 0.0660 - acc: 0.9801 - val_loss: 0.0681 - val_acc: 0.9796
Epoch 6/100
train_acc = 0.984125
49s - loss: 0.0593 - acc: 0.9815 - val_loss: 0.0648 - val_acc: 0.9808
Epoch 7/100
train_acc = 0.988400
50s - loss: 0.0525 - acc: 0.9845 - val_loss: 0.0574 - val_acc: 0.9822
Epoch 8/100
train_acc = 0.987575
51s - loss: 0.0440 - acc: 0.9862 - val_loss: 0.0622 - val_acc: 0.9806
Epoch 9/100
train_acc = 0.990750
49s - loss: 0.0411 - acc: 0.9870 - val_loss: 0.0506 - val_acc: 0.9853
Epoch 10/100
train_acc = 0.991875
49s - loss: 0.0353 - acc: 0.9889 - val_loss: 0.0510 - val_acc: 0.9845
Epoch 11/100
train_acc = 0.991725
48s - loss: 0.0318 - acc: 0.9899 - val_loss: 0.0537 - val_acc: 0.9833
Epoch 12/100
train_acc = 0.991750
49s - loss: 0.0278 - acc: 0.9908 - val_loss: 0.0574 - val_acc: 0.9835
Epoch 13/100
train_acc = 0.992925
49s - loss: 0.0254 - acc: 0.9916 - val_loss: 0.0540 - val_acc: 0.9848
Epoch 14/100
train_acc = 0.992150
49s - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0586 - val_acc: 0.9827
Epoch 15/100
train_acc = 0.992900
51s - loss: 0.0210 - acc: 0.9925 - val_loss: 0.0625 - val_acc: 0.9820
Epoch 16/100
train_acc = 0.994075
49s - loss: 0.0219 - acc: 0.9930 - val_loss: 0.0596 - val_acc: 0.9828
Epoch 17/100
train_acc = 0.996275
48s - loss: 0.0188 - acc: 0.9939 - val_loss: 0.0525 - val_acc: 0.9857
Epoch 18/100
train_acc = 0.994250
50s - loss: 0.0176 - acc: 0.9941 - val_loss: 0.0567 - val_acc: 0.9830
Epoch 19/100
train_acc = 0.996225
48s - loss: 0.0155 - acc: 0.9950 - val_loss: 0.0581 - val_acc: 0.9849
Epoch 20/100
train_acc = 0.996500
49s - loss: 0.0147 - acc: 0.9949 - val_loss: 0.0573 - val_acc: 0.9849
Epoch 21/100
train_acc = 0.997175
50s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0541 - val_acc: 0.9860
Epoch 22/100
train_acc = 0.996025
49s - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0593 - val_acc: 0.9839
Epoch 23/100
train_acc = 0.997625
48s - loss: 0.0127 - acc: 0.9959 - val_loss: 0.0610 - val_acc: 0.9857
Epoch 24/100
train_acc = 0.997575
48s - loss: 0.0121 - acc: 0.9959 - val_loss: 0.0622 - val_acc: 0.9844
Epoch 25/100
train_acc = 0.998350
49s - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0602 - val_acc: 0.9856
Epoch 26/100
train_acc = 0.993875
48s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0738 - val_acc: 0.9819
